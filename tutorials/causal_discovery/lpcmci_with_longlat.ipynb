{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller,kpss\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import gpytorch\n",
    "import tigramite\n",
    "from tigramite import data_processing as pp\n",
    "from tigramite.toymodels import structural_causal_processes as toys\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.lpcmci import LPCMCI\n",
    "#from tigramite.pcmci import PCMCI\n",
    "#from tigramite.independence_tests.parcorr import ParCorr\n",
    "#from statsmodels.tools.sm_exceptions import InterpolationWarning\n",
    "import warnings\n",
    "from tigramite.lpcmci import LPCMCI\n",
    "import seaborn as sns\n",
    "#from tigramite.independence_tests.gpdc import GPDC\n",
    "#from tigramite.independence_tests.gpdc_torch import GPDCtorch\n",
    "from tigramite.independence_tests.cmiknn import CMIknn\n",
    "# from tigramite.independence_tests.cmisymb import CMIsymb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0       1       2       3       4       5       6       7       8    \\\n",
      "0  24.94  24.347  24.347  23.752  23.752  23.153  23.153  22.555  22.555   \n",
      "1  14.95  14.517  14.517  14.085  14.085  13.653  13.653  13.224  13.224   \n",
      "2  23.43  22.732  22.732  22.058  22.058  21.409  21.409  20.777  20.777   \n",
      "3  12.31  12.218  12.218  12.162  12.162  12.136  12.136  12.123  12.123   \n",
      "4  30.45  29.788  29.788  29.125  29.125  28.462  28.462  27.805  27.805   \n",
      "\n",
      "      9    ...     134     135     136     137     138     139     140  \\\n",
      "0  21.965  ...   2.315   2.027   2.027   1.740   1.740   1.450   1.450   \n",
      "1  12.796  ...   8.340   8.649   8.649   8.971   8.971   9.311   9.311   \n",
      "2  20.153  ...   2.322   2.586   2.586   2.854   2.854   3.126   3.126   \n",
      "3  12.107  ...  13.060  13.068  13.068  13.058  13.058  13.037  13.037   \n",
      "4  27.143  ...   5.139   4.986   4.986   4.857   4.857   4.751   4.751   \n",
      "\n",
      "      141     142     143  \n",
      "0   1.159   1.159   0.873  \n",
      "1   9.665   9.665  10.035  \n",
      "2   3.413   3.413   3.711  \n",
      "3  13.014  13.014  12.993  \n",
      "4   4.650   4.650   4.549  \n",
      "\n",
      "[5 rows x 144 columns]\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv('dv_norm_loc.csv', header = None)\n",
    "print(dat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44064, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load Data, Handle Missingness:\n",
    "\n",
    "data = torch.load(f\"/home/gnicolaou/tigramite/tutorials/causal_discovery/combined_tensor.pt\", map_location=torch.device('cpu'))\n",
    "\n",
    "# Number of observed variables\n",
    "#N = data.shape[1]\n",
    "data = data.numpy()\n",
    "data = pd.DataFrame(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1           2          3         4          5  \\\n",
      "0   66.216728  0.078297  292.137177  25.787775  0.000160  10.428891   \n",
      "1  200.731400  0.007993  295.146606  23.221931  0.000240   8.244879   \n",
      "2   24.651501  0.013119  292.934418  23.455170  0.000224  12.020223   \n",
      "3  159.606262  0.001872  294.594208  17.631453  0.007888   2.550540   \n",
      "4   12.181140  0.003811  291.437225  21.168480  0.000320  10.262062   \n",
      "\n",
      "              6         7       8  \n",
      "0 -1.708685e-05  0.902100  24.940  \n",
      "1 -1.117597e-06  0.933838  24.347  \n",
      "2  1.190958e-06  0.901123  24.347  \n",
      "3 -6.610977e-07  0.575684  23.752  \n",
      "4  1.108296e-05  0.645508  23.752  \n"
     ]
    }
   ],
   "source": [
    "array_306_144 = dat.values.flatten()\n",
    "data[8] = array_306_144\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data.values\n",
    "\n",
    "# empty list to store the modified columns to separate trajectories\n",
    "modified_columns = []\n",
    "\n",
    "for col in range(dat.shape[1]):\n",
    "    column_data = dat[:, col]\n",
    "    \n",
    "    # insert 999 values between every 144 elements\n",
    "    modified_column = np.insert(column_data, np.arange(144, column_data.size, 144), 999)\n",
    "    \n",
    "    # append the modified column to the list\n",
    "    modified_columns.append(modified_column)\n",
    "\n",
    "modified_data = np.column_stack(modified_columns)\n",
    "\n",
    "dat = modified_data # handle missingness\n",
    "n_a_n = np.isnan(dat).any(axis=1)\n",
    "dat[n_a_n] = 999\n",
    "#dat = dat[0:1440,:]\n",
    "\n",
    "# initialize dataframe object, specify variable names\n",
    "var_names = ['Nd','Pr','sst','lts','fth','ws','div','cf', 'loc']\n",
    "dataframe = pp.DataFrame(dat, var_names=var_names, missing_flag = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {(0, -1): '-?>', (1, 0): '<?-', (1, -1): '-?>', (2, 0): '-?>', (2, -1): '', (3, 0): '-?>', (3, -1): '', (4, 0): '-?>', (4, -1): '', (5, 0): '-?>', (5, -1): '', (6, 0): '-?>', (6, -1): '', (7, 0): '', (7, -1): '', (8, 0): 'o?o', (8, -1): 'o?>'}, 1: {(0, 0): '-?>', (0, -1): 'o?>', (1, -1): '', (2, 0): '', (2, -1): '', (3, 0): '', (3, -1): '', (4, 0): '', (4, -1): '', (5, 0): '', (5, -1): '', (6, 0): '', (6, -1): '', (7, 0): '-?>', (7, -1): 'o?>', (8, 0): 'o?o', (8, -1): 'o?>'}, 2: {(0, 0): '<?-', (0, -1): '', (1, 0): '', (1, -1): '', (2, -1): '', (3, 0): '', (3, -1): '', (4, 0): '', (4, -1): '', (5, 0): '', (5, -1): '', (6, 0): '', (6, -1): '', (7, 0): '<?-', (7, -1): '', (8, 0): 'o?o', (8, -1): ''}, 3: {(0, 0): '<?-', (0, -1): '', (1, 0): '', (1, -1): '', (2, 0): '', (2, -1): '', (3, -1): '', (4, 0): '', (4, -1): '', (5, 0): '', (5, -1): '', (6, 0): '', (6, -1): '', (7, 0): '<?-', (7, -1): '', (8, 0): 'o?o', (8, -1): ''}, 4: {(0, 0): '<?-', (0, -1): '', (1, 0): '', (1, -1): '', (2, 0): '', (2, -1): '', (3, 0): '', (3, -1): '', (4, -1): '', (5, 0): '', (5, -1): '', (6, 0): '', (6, -1): '', (7, 0): '<?-', (7, -1): '', (8, 0): 'o?o', (8, -1): ''}, 5: {(0, 0): '<?-', (0, -1): '', (1, 0): '', (1, -1): '', (2, 0): '', (2, -1): '', (3, 0): '', (3, -1): '', (4, 0): '', (4, -1): '', (5, -1): '', (6, 0): '', (6, -1): '', (7, 0): '<?-', (7, -1): '', (8, 0): 'o?o', (8, -1): ''}, 6: {(0, 0): '<?-', (0, -1): '', (1, 0): '', (1, -1): '', (2, 0): '', (2, -1): '', (3, 0): '', (3, -1): '', (4, 0): '', (4, -1): '', (5, 0): '', (5, -1): '', (6, -1): '', (7, 0): '<?-', (7, -1): '', (8, 0): 'o?o', (8, -1): ''}, 7: {(0, 0): '', (0, -1): 'o?>', (1, 0): '<?-', (1, -1): '-?>', (2, 0): '-?>', (2, -1): '', (3, 0): '-?>', (3, -1): '', (4, 0): '-?>', (4, -1): '', (5, 0): '-?>', (5, -1): '', (6, 0): '-?>', (6, -1): '', (7, -1): 'o?>', (8, 0): 'o?o', (8, -1): 'o?>'}, 8: {(0, 0): 'o?o', (0, -1): 'o?>', (1, 0): 'o?o', (1, -1): 'o?>', (2, 0): 'o?o', (2, -1): '', (3, 0): 'o?o', (3, -1): '', (4, 0): 'o?o', (4, -1): '', (5, 0): 'o?o', (5, -1): '', (6, 0): 'o?o', (6, -1): '', (7, 0): 'o?o', (7, -1): 'o?>', (8, -1): ''}}\n"
     ]
    }
   ],
   "source": [
    "cmiknn = CMIknn(significance='shuffle_test', knn=0.1, shuffle_neighbors=5, transform='ranks', sig_samples=200)\n",
    "link_assumptions = {j:{(i, -tau):'' for i in range(9) for tau in range(2) if (i, -tau) != (j, 0)} \n",
    "                            for j in range(9)}\n",
    "\n",
    "link_assumptions[0][(1, 0)] = '<?-' #Nd is an ancestor of P\n",
    "link_assumptions[1][(0, 0)] = '-?>'\n",
    "link_assumptions[7][(1, 0)] = '<?-'# CF is an ancestor of precipitation\n",
    "link_assumptions[1][(7, 0)] = '-?>'\n",
    "link_assumptions[0][(0, -1)] = '-?>' #Nd at lag t-1 is an ancestor of Nd\n",
    "link_assumptions[0][(1, -1)] = '-?>' #P at lag t-1 is an ancestor of Nd\n",
    "link_assumptions[7][(1, -1)] = '-?>' #P at lag t-1 is an ancestor of CF\n",
    "\n",
    "link_assumptions[7][(0, -1)] = 'o?>' #Nd at lag t-1 is an ancestor of CF\n",
    "link_assumptions[1][(0, -1)] = 'o?>' #Nd at lag t-1 is an ancestor of P\n",
    "link_assumptions[1][(7, -1)] = 'o?>' #CF at lag t-1 is an ancestor of P\n",
    "link_assumptions[7][(7, -1)] = 'o?>' #CF at lag t-1 is an ancestor of CF\n",
    "\n",
    "for j in range(2,7): \n",
    "    link_assumptions[j][(0, 0)] = '<?-' #meterological variables are ancestor of aerosol\n",
    "    link_assumptions[0][(j, 0)] = '-?>'\n",
    "    link_assumptions[j][(7, 0)] = '<?-' #meteorological variables are ancestor of cloud fraction\n",
    "    link_assumptions[7][(j, 0)] = '-?>'\n",
    "    link_assumptions[j][(8,0)] = 'o?o' #meteorological variables has a link wth location\n",
    "    link_assumptions[8][(j,0)] = 'o?o'\n",
    "\n",
    "link_assumptions[0][(8, 0)] = 'o?o' #Nd has any link with location contemporaneously\n",
    "link_assumptions[8][(0, 0)] = 'o?o' \n",
    "link_assumptions[1][(8, 0)] = 'o?o' #P has any link with location contemporaneously\n",
    "link_assumptions[8][(1, 0)] = 'o?o' \n",
    "link_assumptions[7][(8, 0)] = 'o?o' #CF has any link with location contemporaneously\n",
    "link_assumptions[8][(7, 0)] = 'o?o' \n",
    "link_assumptions[0][(8, -1)] = 'o?>' #Nd has any link with location at lag t - 1\n",
    "link_assumptions[8][(0, -1)] = 'o?>' \n",
    "link_assumptions[1][(8, -1)] = 'o?>' #P has any link with location at lag t - 1\n",
    "link_assumptions[8][(1, -1)] = 'o?>' \n",
    "link_assumptions[7][(8, -1)] = 'o?>' #CF has any link with location at lag t - 1\n",
    "link_assumptions[8][(7, -1)] = 'o?>' \n",
    "print(link_assumptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "=======================================================\n",
      "Starting preliminary phase  1\n",
      "\n",
      "Starting test phase\n",
      "\n",
      "p = 0\n"
     ]
    }
   ],
   "source": [
    "lpcmci_loc = LPCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=cmiknn,\n",
    "    verbosity=1)\n",
    "results = lpcmci_loc.run_lpcmci(tau_max=2, pc_alpha=.05, link_assumptions = link_assumptions)\n",
    "tp.plot_time_series_graph(graph=results['graph'],\n",
    "                          val_matrix=results['val_matrix'], save_name = \"cmiknn_w_loc.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
